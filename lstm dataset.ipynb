{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import planarity\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "df_0, df_1, df_2, df_3, df_4, df_5, df_6 = load_data()\n",
    "\n",
    "df_6.drop(columns=['A060000','A002860'],inplace=True)\n",
    "\n",
    "\n",
    "train_start_day = '2017-01-03'\n",
    "train_end_day = '2020-03-20'\n",
    "\n",
    "valid_start_day = '2020-03-23'\n",
    "valid_end_day = '2020-11-02'\n",
    "\n",
    "test_start_day = '2020-11-03'\n",
    "test_end_day = '2021-09-30'\n",
    "\n",
    "\n",
    "#lstm에서는 이게 중요.\n",
    "seq_length = 100\n",
    "rebal_term = 20\n",
    "often_freq = 1\n",
    "\n",
    "# 정적인 자산 운용. 미리 stock을 정해놓고 들어간다.\n",
    "# 모든 idx는 iloc으로 접근한다.\n",
    "\n",
    "df_list = [df_0, df_1, df_2, df_3, df_4, df_5, df_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_stocks\n",
    "#get the iloc of train_start_day from df_open\n",
    "train_start_idx = df_0.index.get_loc(train_start_day)\n",
    "test_start_idx = df_0.index.get_loc(test_start_day)\n",
    "\n",
    "selected_stocks = select_stocks(df_list, train_start_idx, test_start_idx, 50, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "\n",
    "class LSTMCustomDataset(Dataset):\n",
    "    '''\n",
    "    init 변수 설명.\n",
    "    \n",
    "    df_list : [df_open, df_high, df_low, df_close, df_vol, df_index, df_markets]\n",
    "    stock_list: 미리 뽑아 둔 주식리스트를 활용한다. select_stocks 함수 이용.\n",
    "    start_date : Train/val/test 처음에 자를 날짜. 이 때 인자로서는 train/val/test별로 다르게 들어가야함.\n",
    "    end_date: Train/val/test 나중에 자를 날짜. 이 때 인자로서는 train/val/test별로 다르게 들어가야함.\n",
    "    seq_length : LSTM에 들어갈 sequence length -> 20, 100 모두 진행할 것.\n",
    "    rebal_term : 리밸런싱을 할 term -> 며칠 뒤의 라벨을 맞출 것인가. -> 이건 20 영업일 뒤로\n",
    "    often_freq : 데이터를 뽑아낼 주기. 여기선 모두 1로 둔다.\n",
    "    \n",
    "    rebal_idx_list: 시퀀스를 만들어낼 리밸런싱 날짜들의 인덱스를 저장해둔 리스트. 그래프 시퀀스는 리밸런싱 날짜를 기준으로 하나씩 만들어짐.\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, df_list, stock_list, start_date, end_date, seq_length, rebal_term, often_freq, device):\n",
    "        self.stock_list = stock_list\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.seq_length = seq_length\n",
    "        self.rebal_term = rebal_term\n",
    "        self.often_freq = often_freq\n",
    "        self.device = device\n",
    "        # 스케일링을 적용할 데이터 프레임 복사 및 스케일링\n",
    "        self.df_open = standard_scale_feature(df_list[0],pd.to_datetime(self.start_date), pd.to_datetime(self.end_date))\n",
    "        self.df_high = standard_scale_feature(df_list[1],pd.to_datetime(self.start_date), pd.to_datetime(self.end_date))\n",
    "        self.df_low = standard_scale_feature(df_list[2], pd.to_datetime(self.start_date), pd.to_datetime(self.end_date))\n",
    "        self.df_close = standard_scale_feature(df_list[3], pd.to_datetime(self.start_date), pd.to_datetime(self.end_date))\n",
    "        self.df_vol = standard_scale_feature(df_list[4], pd.to_datetime(self.start_date), pd.to_datetime(self.end_date))\n",
    "        self.df_index = df_list[5]  # 인덱스는 스케일링하지 않음\n",
    "        self.df_markets = df_list[6]  # 시장 데이터는 스케일링하지 않음\n",
    "        self.df_close_notscaled = df_list[3].copy()  # 라벨 생성에 사용할 원본 종가 데이터\n",
    "\n",
    "        self.rebal_idx_list = []\n",
    "        self.stocks_list = []\n",
    "    \n",
    "        self.make_rebal_idx_list()\n",
    "\n",
    "    def make_labels(self, selected_stocks_final, rebal_idx):\n",
    "\n",
    "        # 코스피 인덱스의 로그 리턴 구하기\n",
    "        future_index_prices = self.df_index.iloc[rebal_idx+self.rebal_term].values[0]\n",
    "        current_index_prices = self.df_index.iloc[rebal_idx].values[0]\n",
    "        \n",
    "        index_log_return = np.log(((future_index_prices+1e-6)/(current_index_prices+1e-6))+1e-6)\n",
    "        \n",
    "        # 선택된 주식들의 로그 리턴 구하기\n",
    "        future_close_prices = self.df_close_notscaled[selected_stocks_final].iloc[rebal_idx+self.rebal_term].values\n",
    "        current_close_prices = self.df_close_notscaled[selected_stocks_final].iloc[rebal_idx].values\n",
    "        \n",
    "        close_log_returns = np.log((future_close_prices+1e-6)/(current_close_prices+1e-6)+1e-6)\n",
    "        \n",
    "        # 라벨 만들기\n",
    "        labels = [1 if close_log_return > index_log_return else 0 for close_log_return in close_log_returns]  # 20일 뒤에 인덱스보다 먹으면 0      \n",
    "        \n",
    "        return labels\n",
    "\n",
    "\n",
    "\n",
    "    def make_rebal_idx_list(self):\n",
    "        '''\n",
    "        데이터셋 만들 때, 시퀀스를 만들 날짜들을 만드는 함수\n",
    "        '''\n",
    "        \n",
    "        if not isinstance(self.start_date, pd.Timestamp):\n",
    "            self.start_date = pd.to_datetime(self.start_date)\n",
    "        if not isinstance(self.end_date, pd.Timestamp):\n",
    "            self.end_date = pd.to_datetime(self.end_date)\n",
    "        \n",
    "        start_idx = self.df_open.index.get_loc(self.start_date)\n",
    "        end_idx = self.df_open.index.get_loc(self.end_date)\n",
    "        self.rebal_idx_list = list(range(start_idx, end_idx, self.often_freq))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # 데이터 준비 로직 변경\n",
    "        self.time_series_data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for rebal_idx in self.rebal_idx_list:\n",
    "            selected_stocks_final = self.stock_list\n",
    "            \n",
    "            # 시계열 데이터를 저장할 리스트 초기화\n",
    "            sequence_data = []\n",
    "            \n",
    "            for past_days in range(self.seq_length, 0, -1):\n",
    "                # 각 시점에 대한 특성 데이터 추출\n",
    "                features = []\n",
    "                for stock in selected_stocks_final:\n",
    "                    features.append([\n",
    "                        self.df_open[stock].iloc[rebal_idx - past_days],\n",
    "                        self.df_open[stock].iloc[rebal_idx - past_days-self.rebal_term],\n",
    "                        self.df_high[stock].iloc[rebal_idx - past_days],\n",
    "                        self.df_high[stock].iloc[rebal_idx - past_days-self.rebal_term],\n",
    "                        self.df_low[stock].iloc[rebal_idx - past_days],\n",
    "                        self.df_low[stock].iloc[rebal_idx - past_days-self.rebal_term],\n",
    "                        self.df_close[stock].iloc[rebal_idx - past_days],\n",
    "                        self.df_close[stock].iloc[rebal_idx-past_days-self.rebal_term],\n",
    "                        self.df_vol[stock].iloc[rebal_idx - past_days],\n",
    "                        self.df_vol[stock].iloc[rebal_idx - past_days-self.rebal_term]\n",
    "                    ])\n",
    "                sequence_data.append(features)\n",
    "            labels = self.make_labels(selected_stocks_final, rebal_idx)\n",
    "            \n",
    "            self.time_series_data.append(np.array(sequence_data))\n",
    "            self.labels.append(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.time_series_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence_data = torch.tensor(self.time_series_data[idx], dtype=torch.float).to(self.device)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.long).to(self.device)\n",
    "\n",
    "        return sequence_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with different labels: [3, 15]\n"
     ]
    }
   ],
   "source": [
    "first_labels = test_lstm_dataset.labels[0]\n",
    "second_labels = test_lstm_dataset.labels[1]\n",
    "\n",
    "# 값이 다른 인덱스만 찾기\n",
    "different_indices = [i for i, (first, second) in enumerate(zip(first_labels, second_labels)) if first != second]\n",
    "\n",
    "print(\"Indices with different labels:\", different_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_lstm_dataset = LSTMCustomDataset(df_list, selected_stocks, train_start_day, train_end_day, seq_length, rebal_term, often_freq,device)\n",
    "train_lstm_dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "valid_lstm_dataset = LSTMCustomDataset(df_list, selected_stocks, valid_start_day, valid_end_day, seq_length, rebal_term, often_freq,device)\n",
    "valid_lstm_dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "test_lstm_dataset = LSTMCustomDataset(df_list, selected_stocks, test_start_day, test_end_day, seq_length, rebal_term, often_freq,device)\n",
    "test_lstm_dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "786개 rebal_idx 마다 100일의 sequence가 만들어지고, 이 떄는 각 stock마다 10개의 stock indicator을 담은 정보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_stocks, dropout=0.2):\n",
    "        super(MultiLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_stocks = num_stocks\n",
    "        \n",
    "        # 각 주식별로 LSTM 모델을 만들기 위한 ModuleList\n",
    "        self.lstm_list = nn.ModuleList([nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout) \n",
    "                                         for _ in range(num_stocks)])\n",
    "        \n",
    "        # 각 주식별로 다른 fully connected layer를 만들기 위한 ModuleList\n",
    "        self.fc_list = nn.ModuleList([nn.Linear(hidden_size, output_size) for _ in range(num_stocks)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(self.num_stocks):\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "            out, _ = self.lstm_list[i](x[:, i, :, :].squeeze(1), (h0, c0))\n",
    "            out = self.dropout(out[:, -1, :])\n",
    "            out = self.fc_list[i](out)\n",
    "            outputs.append(out.unsqueeze(1))  # 주식별 예측을 3차원 텐서로 만들기 위해 unsqueeze 사용\n",
    "        outputs = torch.cat(outputs, dim=1)  # [배치 크기, 주식 수, 클래스 수] 형태로 변환\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(train_dataloader, valid_dataloader, seed, num_epochs, hidden_size, num_classes, num_stocks, input_size, num_layers, dropout, device, seq_length, rebal_term, patience=10):\n",
    "    \n",
    "    model = MultiLSTMModel(input_size, hidden_size, num_layers, num_classes, num_stocks, dropout)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-6)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # outputs 크기: [배치 크기, 주식 수, 클래스 수]\n",
    "\n",
    "            loss = 0\n",
    "            for j in range(outputs.size(1)):  # 주식 수만큼 반복\n",
    "                loss += criterion(outputs[:, j, :], labels[:, j])\n",
    "            loss /= outputs.size(1)  # 평균 손실 계산\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_dataloader)\n",
    "        \n",
    "        # 검증 과정\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(valid_dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = 0\n",
    "                for j in range(outputs.size(1)):  # 주식 수만큼 반복\n",
    "                    loss += criterion(outputs[:, j, :], labels[:, j])\n",
    "                loss /= outputs.size(1)  # 평균 손실 계산\n",
    "\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(valid_dataloader)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_weights = model.state_dict()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter > patience:\n",
    "                    print(f\"Early stopping triggered. Stopping training at epoch {epoch}\")\n",
    "                    break\n",
    "    \n",
    "    if best_model_weights is not None:\n",
    "        model_path = f'./checkpoints/best_lstm_model_{seed}_{seq_length}_{rebal_term}.pth'\n",
    "        torch.save(best_model_weights, model_path)\n",
    "        print(f\"Best LSTM model weights saved successfully at {model_path}.\")\n",
    "    \n",
    "    best_lstm = MultiLSTMModel(input_size, hidden_size, num_layers, num_classes, num_stocks, dropout)\n",
    "    best_lstm.load_state_dict(torch.load(model_path))\n",
    "    best_lstm.to(device)\n",
    "    best_lstm.eval()\n",
    "    \n",
    "    return best_lstm, outputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. Stopping training at epoch 24\n",
      "Best LSTM model weights saved successfully at ./checkpoints/best_lstm_model_42_100_20.pth.\n"
     ]
    }
   ],
   "source": [
    "# 데이터로더 설정 및 모델 학습\n",
    "num_stocks = len(selected_stocks)  # 주식 종목 수\n",
    "input_size = 10  # 입력 특성 수\n",
    "hidden_size = 64  # LSTM 은닉 상태 크기\n",
    "num_layers = 2  # LSTM 층 수\n",
    "num_classes = 2  # 이진 분류이므로 출력 크기는 2\n",
    "dropout = 0.2  # 드롭아웃 비율\n",
    "num_epochs = 100\n",
    "\n",
    "train_dataloader = DataLoader(train_lstm_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_lstm_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_lstm_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# SEED 설정\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 학습 함수 호출\n",
    "best_lstm, outputs, labels = train_lstm(train_dataloader, valid_dataloader, seed=seed, num_epochs=num_epochs, hidden_size=hidden_size,\n",
    "                       num_classes=num_classes, num_stocks=num_stocks, input_size=input_size, num_layers=num_layers,\n",
    "                       dropout=dropout, device=device, seq_length=seq_length, rebal_term=rebal_term, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm(test_dataloader, input_size, hidden_size, num_layers, num_classes, num_stocks, dropout, device, model_path):\n",
    "    # 모델 초기화\n",
    "    model = MultiLSTMModel(input_size, hidden_size, num_layers, num_classes, num_stocks, dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    # 저장된 state_dict 불러오기\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    outputs_list = []\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산을 비활성화\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # 모델을 통해 추론 실행\n",
    "            _, predicted = torch.max(outputs, dim=2)  # 가장 높은 점수를 가진 클래스를 선택\n",
    "            outputs_list.append(outputs)\n",
    "            all_predictions.append(predicted.cpu().numpy())  # 예측 결과 저장\n",
    "            all_labels.append(labels.cpu().numpy())  # 실제 라벨 저장\n",
    "\n",
    "    # 결과를 numpy 배열로 변환\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_predictions, all_labels, outputs_list\n",
    "\n",
    "\n",
    "model_path = f\"./checkpoints/best_lstm_model_{seed}_{seq_length}_{rebal_term}.pth\"\n",
    "all_predictions, all_labels, outputs_list = test_lstm(test_dataloader, input_size, hidden_size, num_layers, num_classes, num_stocks, dropout, device, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLSTMModel(input_size, hidden_size, num_layers, num_classes, num_stocks, dropout)\n",
    "model.to(device)\n",
    "model_path = f'./checkpoints/best_lstm_model_{seed}_{seq_length}_{rebal_term}.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "def test_lstm(model, test_dataset):\n",
    "    model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_preds.append(outputs)\n",
    "            test_labels.append(labels)\n",
    "            \n",
    "            for i in range(outputs.size(0)):\n",
    "                for j in range(outputs.size(1)):\n",
    "                    result = torch.argmax(outputs[i, j]).item() == labels[i, j].item()\n",
    "                    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm(test_dataloader, input_size, hidden_size, num_layers, num_classes, num_stocks, dropout, device, model_path):\n",
    "    # 모델 초기화\n",
    "    \n",
    "\n",
    "    # 저장된 state_dict 불러오기\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    outputs_list = []\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산을 비활성화\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # 모델을 통해 추론 실행\n",
    "            softmax_output = torch.softmax(outputs, dim=1)  # 가장 높은 점수를 가진 클래스를 선택\n",
    "            outputs_list.append(outputs)\n",
    "            preds = torch.argmax(softmax_output, dim=1).cpu.numpy()\n",
    "            \n",
    "            one_preds = []\n",
    "            zero_preds = []\n",
    "            for idx, pred in enumerate(preds):\n",
    "                if pred == 1:\n",
    "                    one_preds.append(idxm softmax_output[idx])\n",
    "                else:\n",
    "                    zero_preds.append(idx)\n",
    "            \n",
    "            \n",
    "\n",
    "    # 결과를 numpy 배열로 변환\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_predictions, all_labels, outputs_list\n",
    "\n",
    "\n",
    "model_path = f\"./checkpoints/best_lstm_model_{seed}_{seq_length}_{rebal_term}.pth\"\n",
    "all_predictions, all_labels, outputs_list = test_lstm(test_dataloader, input_size, hidden_size, num_layers, num_classes, num_stocks, dropout, device, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_list[0][0][0]) # 배치개수 * 배치사이즈가 있고, 각 배치사이즈마다 30개의 주식에 대한 각 2가지 경우에 대한 예측이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongwoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
